{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57cb86e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "sys.path.append('src/')\n",
    "sys.dont_write_bytecode = True\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
    "import transformers\n",
    "import torch\n",
    "import transformers \n",
    "import torch\n",
    "from util import unshard_deepspeed, generate_text\n",
    "\n",
    "# Llama 7b memory footprint with LORA r = 16\n",
    "\n",
    "# When create - use a large disk for the checkpoints\n",
    "\n",
    "# Inference 16bit - 13gb, 8bit - 8gb\n",
    "\n",
    "# Train 2batch - 16bit -  > 49 gb\n",
    "# Train 2batch - deepspeed_stage_2 - 16bit -  27gb\n",
    "# Train 4batch - deepspeed_stage_2 - 16bit -  38gb\n",
    "# Train 4batch - deepspeed_stage_2 - 16bit -  43gb\n",
    "# Train 4batch - deepspeed_stage_3 - 16bit -  45gb\n",
    "# Train 6batch - deepspeed_stage_2 - 16bit -  > 49gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21096f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reacher.reacher import Reacher, ReacherDocker, RemoteClient\n",
    "from reacher.reacher import create_notebook, create_tensorboard\n",
    "\n",
    "reacher = Reacher(\n",
    "    build_name=\"training_alpacha_lora\",\n",
    "    host=\"\",\n",
    "    port=8961,\n",
    "    user=\"root\",\n",
    "    ssh_key_filepath=\".ssh/id_rsa\",\n",
    "    prefix_cmd=\"PATH=/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home//.local/bin\"\n",
    ")\n",
    "\n",
    "reacher.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87e9f13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 16 08:29:11 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:1B:00.0 Off |                  Off |\r\n",
      "| 30%   32C    P8    19W / 300W |      0MiB / 49140MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:B2:00.0 Off |                  Off |\r\n",
      "| 30%   29C    P8    18W / 300W |      0MiB / 49140MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "reacher.execute_command(\"nvidia-smi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a notebook session on the remote and do port-forwarding between the remote and your local \n",
    "create_notebook(reacher, remote_port=55068, local_port=55068)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7540e645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard running on\n",
      "http://0.0.0.0:55069/\n"
     ]
    }
   ],
   "source": [
    "# Create a tensorboard session on the remote and do port-forwarding between the remote and your local \n",
    "create_tensorboard(reacher, remote_port=55069, local_port=55069, logdir=reacher.build_path+\"/artifacts/runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71f7737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a screen on:\r",
      "\r\n",
      "\t7704.tensorboard\t(04/16/23 08:46:05)\t(Attached)\r\n",
      "1 Socket in /run/screen/S-root.\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "reacher.list_named_sessions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e46df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacher.kill_named_session(\"tensorboard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a530dc5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f008d5a",
   "metadata": {},
   "source": [
    "### Send all data to the remote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc72611",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacher.put([\"src\", \"data\", \"config.yaml\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c473d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process the data\n",
    "reacher.execute(\n",
    "    \"python src/setup.py --local --model 'decapoda-research/llama-7b-hf' --data_file alpaca_data_cleaned.json --max_tokens 512\",\n",
    "    context=[\"src\", \"data/alpaca_data_cleaned.json\"],\n",
    "    wrap_in_screen=True,\n",
    "    named_session=\"setup\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a1712",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "reacher.execute(\n",
    "    \"python src/train_lightning.py --config config.yaml --local\",\n",
    "    context=[\"src\", \"config.yaml\"],\n",
    "    wrap_in_screen=True,\n",
    "    named_session=\"training\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "490233c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 16 10:05:51 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:1B:00.0 Off |                  Off |\r\n",
      "| 59%   83C    P2   284W / 300W |  46816MiB / 49140MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  NVIDIA RTX A6000    Off  | 00000000:B2:00.0 Off |                  Off |\r\n",
      "| 47%   73C    P2   278W / 300W |  46116MiB / 49140MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "reacher.execute_command(\"nvidia-smi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402bd118",
   "metadata": {},
   "outputs": [],
   "source": [
    "reacher.kill_named_session(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07bcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the checkpoint\n",
    "reacher.get(\"artifacts...../final.ckpt\", \"weights/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b005981b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
